train_loss,val_loss,val_accuracy
1.3603614018513606,1.3365557789802551,27.636363636363637
1.3237118537609394,1.3000012636184692,27.636363636363637
1.2873956790337195,1.261737883090973,43.72727272727273
1.2369425205083995,1.207240343093872,45.72727272727273
1.187431583037743,1.1444302797317505,50.0
1.1288723945617676,1.0805680751800537,54.272727272727266
1.0760943935467646,1.0307300686836243,54.54545454545455
1.0485697067700899,0.9968560636043549,59.81818181818182
1.0446694722542396,0.9750877618789673,61.81818181818181
0.9967343577971826,0.9478183388710022,61.54545454545455
0.9835807176736685,0.9412612318992615,59.54545454545455
0.9701102788631732,0.9216196835041046,58.272727272727266
0.9575993281144363,0.9122395813465118,62.81818181818181
0.9064800555889423,0.8918172717094421,62.81818181818181
0.9280354197208698,0.8891552686691284,63.54545454545455
0.9387045135864844,0.8835977613925934,65.81818181818181
0.8991938600173364,0.8723519444465637,67.81818181818181
0.8905705763743474,0.8717235028743744,63.81818181818181
0.8721334888384893,0.8646352887153625,64.54545454545455
0.8869001590288602,0.8632714748382568,66.81818181818181
0.8861609743191645,0.8578283488750458,66.81818181818181
0.837572808449085,0.8621722757816315,63.54545454545455
0.8345166032130902,0.8589580357074738,63.54545454545455
0.8296565917822031,0.8566194176673889,65.81818181818181
0.832344114780426,0.8521804213523865,63.272727272727266
0.8046418841068561,0.8471604585647583,66.81818181818181
0.8143883989407465,0.8515051305294037,66.54545454545455
0.8194146568958576,0.852982759475708,67.81818181818181
0.7646869191756616,0.8468035459518433,66.54545454545455
0.7879447157566364,0.8531103730201721,68.81818181818181



#STOPGRAPHDATA

Reduced_DataSet: YES
filter_sizes=[2, 3, 4],
num_filters=[2, 2, 2],
Learning Rate = 0.3







Training complete! Best accuracy: 68.82%.
FINISHED TRAINING
EVALUATING
Average test loss: 0.7792, Accuracy: 0.7125
Precision: 0.7080, Recall: 0.7123, F1-score: 0.7095, AUC-ROC: 0.8081
Confusion Matrix: 
[[17  1  1  0]
 [ 0 17  2  3]
 [ 1  2 12  4]
 [ 2  3  4 11]]
Classification Report: 
              precision    recall  f1-score   support

           0       0.85      0.89      0.87        19
           1       0.74      0.77      0.76        22
           2       0.63      0.63      0.63        19
           3       0.61      0.55      0.58        20

    accuracy                           0.71        80
   macro avg       0.71      0.71      0.71        80
weighted avg       0.71      0.71      0.71        80