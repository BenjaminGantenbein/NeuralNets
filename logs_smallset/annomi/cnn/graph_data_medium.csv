train_loss,val_loss,val_accuracy
1.3389619405453022,1.2935830354690552,55.54545454545455
1.2641330774013813,1.2097342610359192,68.63636363636363
1.174759103701665,1.0973325967788696,69.63636363636363
1.0648698531664336,0.9721214175224304,67.36363636363637
0.9694829308069669,0.8736299276351929,67.36363636363637
0.8926213154425988,0.8154715597629547,66.0909090909091
0.8357837337713975,0.7737285196781158,71.63636363636363
0.7971541285514832,0.7495100498199463,69.36363636363637
0.7782649581248944,0.7280758321285248,68.36363636363637
0.7512930769186753,0.7211141586303711,67.36363636363637
0.7322060695061317,0.7142185568809509,66.36363636363637
0.699484068613786,0.7110016644001007,67.0909090909091
0.6942271544383123,0.6894155442714691,68.36363636363637
0.659071147441864,0.7130881547927856,69.36363636363637
0.6241208819242624,0.6852089166641235,69.36363636363637
0.6090448452876165,0.6818910539150238,70.36363636363637
0.5829241092388446,0.7028509676456451,69.36363636363637
0.5576570675923274,0.6692096590995789,70.36363636363637
0.5315024715203506,0.6860284507274628,69.36363636363637
0.5202874976855058,0.6628629267215729,72.63636363636363
0.4927925192392789,0.6480104923248291,71.63636363636363
0.4728196905209468,0.6499419212341309,71.36363636363637
0.4442608539874737,0.6644747853279114,71.36363636363637
0.42324676421972424,0.6524536609649658,71.36363636363637
0.3874491499020503,0.6465367674827576,70.36363636363637
0.3792235759588388,0.6553026139736176,71.36363636363637
0.36135392578748554,0.6541021168231964,71.36363636363637
0.3480429213780623,0.6547707617282867,71.36363636363637
0.3257463207611671,0.646443098783493,72.63636363636363
0.30860866376986873,0.631185919046402,71.36363636363637


#STOPGRAPHDATA

Reduced_DataSet: YES
filter_sizes=[2, 3, 4],
num_filters=[50, 50, 50],
Learning Rate = 0.3







Training complete! Best accuracy: 72.64%.
FINISHED TRAINING
EVALUATING
Average test loss: 0.6358, Accuracy: 0.7500
Precision: 0.7429, Recall: 0.7432, F1-score: 0.7403, AUC-ROC: 0.8299
Confusion Matrix: 
[[16  1  0  2]
 [ 0 21  1  0]
 [ 1  3 10  5]
 [ 1  1  5 13]]
Classification Report: 
              precision    recall  f1-score   support

           0       0.89      0.84      0.86        19
           1       0.81      0.95      0.88        22
           2       0.62      0.53      0.57        19
           3       0.65      0.65      0.65        20

    accuracy                           0.75        80
   macro avg       0.74      0.74      0.74        80
weighted avg       0.74      0.75      0.74        80