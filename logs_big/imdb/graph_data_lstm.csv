train_loss,val_loss,val_accuracy
0.692773279021768,0.689963698387146,52.75
0.6657233097973991,0.5869981050491333,79.0
0.46869516372680664,0.5046906173229218,78.0
0.37404855910469503,0.5787107348442078,72.75
0.3591487530399771,0.5238012969493866,78.75
0.3431974403998431,0.5424853563308716,76.5
0.3422544195371516,0.5323092043399811,77.75
0.35253310028244467,0.5225867331027985,78.75
0.3418193512103137,0.506236344575882,80.0
0.33175063834470864,0.5016554296016693,81.0
0.33438316162894755,0.4975230097770691,81.5
0.32457396388053894,0.49535250663757324,81.0
0.3207448124885559,0.4770751893520355,83.5
0.31962667843874765,0.4848201274871826,82.0
0.31837708459180947,0.48656290769577026,82.0
0.31821638345718384,0.4882252365350723,82.0
0.3181902888943167,0.49216732382774353,80.75
0.31815483114298654,0.49384477734565735,80.75
0.31813352774171266,0.49596163630485535,80.75
0.31811847406275134,0.4965634346008301,80.75
0.31809370833284717,0.49755363166332245,80.75
0.31808846312410693,0.4981125295162201,80.75
0.3180792997865116,0.4986046105623245,80.75
0.318078875541687,0.4988282024860382,80.75
0.3180583803092732,0.49883443117141724,80.75
0.3180544621804181,0.4989495277404785,80.75
0.31804990768432617,0.499088853597641,80.75
0.3180459281977485,0.499240905046463,80.75
0.3180575511034797,0.49943484365940094,80.75
0.3180362459491281,0.49964623153209686,80.75
0.31803292561979857,0.4997304379940033,80.75
0.3180266723913305,0.4998880624771118,80.75
0.3180295176365796,0.5000630617141724,80.75
0.31802840793834014,0.5002913624048233,80.75
0.3180214885403128,0.5005040019750595,80.75
0.3180193024523118,0.5007535666227341,80.75
0.3180164098739624,0.5009588599205017,80.75
0.31801726186976714,0.501250684261322,80.75
0.3180171075989218,0.5015865862369537,80.75
0.31801644493551817,0.5016482770442963,80.75

#END OF GRAPH
Reduced_DataSet: NO
Layers=2, Bidirectional = True
Learning Rate = 0.001
HiddenSize = 128
Adam


Training complete! Best accuracy: 83.50%.
FINISHED TRAINING
EVALUATING
Average test loss: 0.4549, Accuracy: 0.8600
Precision: 0.8580, Recall: 0.8580, F1-score: 0.8580, AUC-ROC: 0.8580
Confusion Matrix: 
[[37  7]
 [ 7 49]]
Classification Report: 
              precision    recall  f1-score   support

           0       0.84      0.84      0.84        44
           1       0.88      0.88      0.88        56

    accuracy                           0.86       100
   macro avg       0.86      0.86      0.86       100
weighted avg       0.86      0.86      0.86       100