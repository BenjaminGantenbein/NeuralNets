train_loss,val_loss,val_accuracy
0.6938837661462671,0.6938622891902924,47.25
0.692635294269113,0.6923114657402039,52.75
0.6920845052775215,0.6932359337806702,47.25
0.6928350644953111,0.6929434537887573,47.25
0.6939553583369535,0.692285567522049,59.75
0.6922744477496428,0.6915534436702728,52.75
0.6943181647973902,0.6916418969631195,52.75
0.6935415548436782,0.6908419132232666,52.75
0.6949479755233315,0.6914995610713959,52.75
0.6927181166761062,0.6925459802150726,47.25
0.6931772898225224,0.695854902267456,47.25
0.693971756626578,0.6932852566242218,47.25
0.69305099809871,0.691666454076767,56.5
0.693423495573156,0.6910482943058014,53.0
0.6909561542903676,0.6906282901763916,54.0
0.6933491265072542,0.6906597912311554,53.0
0.6921632815809811,0.6912370324134827,54.5
0.6927929660853218,0.6910319328308105,52.25
0.6926085843759424,0.691092848777771,59.0
0.6932331358685213,0.6894403100013733,58.5
0.6923034015823814,0.6901440918445587,62.5
0.691418682827669,0.6888710558414459,58.75
0.6917223229127771,0.6884282827377319,58.75
0.6946034466519075,0.6898912191390991,60.25
0.6923701587845298,0.6885538995265961,56.5
0.693011999130249,0.6886345148086548,59.75
0.6926963434499853,0.6890852153301239,53.25
0.6928657118011924,0.6888627111911774,60.25
0.6906824602800257,0.6875611841678619,57.5
0.6924933685975916,0.6880671679973602,56.75
0.6896551496842328,0.688973605632782,57.5
0.6897596401326797,0.6858811974525452,55.50000000000001
0.6924944449873531,0.6871385276317596,52.0
0.6913788353695589,0.6889588534832001,54.75
0.6932914151864893,0.6869932115077972,61.5
0.6902814682792214,0.6856676340103149,59.75
0.689439033760744,0.6862713098526001,60.25
0.6893734616391799,0.683437168598175,52.0
0.6862592206281775,0.6832651495933533,54.25
0.6904297085369334,0.6817174255847931,59.75



#END OF GRAPH
Reduced_DataSet: NO
HiddenSize = 64
Learning Rate = 0.9
Adam


Training complete! Best accuracy: 62.50%.
FINISHED TRAINING
EVALUATING
Average test loss: 0.6891, Accuracy: 0.5200
Precision: 0.5130, Recall: 0.5130, F1-score: 0.5130, AUC-ROC: 0.5130
Confusion Matrix: 
[[20 24]
 [24 32]]
Classification Report: 
              precision    recall  f1-score   support

           0       0.45      0.45      0.45        44
           1       0.57      0.57      0.57        56

    accuracy                           0.52       100
   macro avg       0.51      0.51      0.51       100
weighted avg       0.52      0.52      0.52       100