train_loss,val_loss,val_accuracy
0.6932828812038198,0.6924120187759399,48.5
0.6896249862278209,0.6873913407325745,65.25
0.6792222401675057,0.682112991809845,53.5
0.6767953774508308,0.677835613489151,67.0
0.6700816470033982,0.672743022441864,67.0
0.658651187139399,0.6718184053897858,58.0
0.6527614207828746,0.6615225970745087,75.25
0.6420096369350657,0.6534214913845062,78.25
0.6316672212937299,0.6448029279708862,80.25
0.6195101983406964,0.6353923380374908,80.5
0.6006917147075429,0.6260903477668762,73.25
0.5920418956700493,0.6145142614841461,74.75
0.5714438592686373,0.6004224717617035,75.25
0.5473715101971346,0.586116373538971,75.25
0.5355466446455788,0.5713617503643036,80.25
0.5068303592064801,0.560614824295044,78.0
0.4788668155670166,0.5385926365852356,79.5
0.45749692005269665,0.5204323083162308,83.25
0.4395683285068063,0.5034401118755341,83.25
0.4122865831150728,0.4873477965593338,82.75
0.3965742412735434,0.4695904850959778,84.25
0.3728693267878364,0.4548567533493042,83.0
0.3467967352446388,0.44452565908432007,81.75
0.3337802571408889,0.4291363060474396,82.75
0.3132488762631136,0.4130261540412903,85.5
0.3070298380711499,0.40237294137477875,87.75
0.27625801195116606,0.3898759186267853,85.5
0.2816796320326188,0.38498203456401825,86.75
0.2649711458122029,0.377285972237587,84.25
0.23664867790306315,0.36391681432724,86.75
0.23717105388641357,0.36343222856521606,84.75
0.22618168855414672,0.35803236067295074,84.75
0.21016073840505936,0.34459948539733887,87.75
0.19598584403009975,0.33754047751426697,86.75
0.1877702229163226,0.35496146976947784,82.5
0.18432656193480773,0.3265596479177475,86.75
0.17927550480646245,0.3290800452232361,85.75
0.16322634719750462,0.3171378821134567,88.0
0.15744286074357874,0.31561312079429626,86.75
0.14155527072794297,0.310634046792984,88.0


#END OF GRAPH
Reduced_DataSet: NO
filter_sizes=[2, 3, 4],
num_filters=[20, 20, 20],
Learning Rate = 0.1
Adam



Training complete! Best accuracy: 88.00%.
FINISHED TRAINING
EVALUATING
Average test loss: 0.3546, Accuracy: 0.8700
Precision: 0.8689, Recall: 0.8742, F1-score: 0.8694, AUC-ROC: 0.8742
Confusion Matrix: 
[[40  4]
 [ 9 47]]
Classification Report: 
              precision    recall  f1-score   support

           0       0.82      0.91      0.86        44
           1       0.92      0.84      0.88        56

    accuracy                           0.87       100
   macro avg       0.87      0.87      0.87       100
weighted avg       0.88      0.87      0.87       100