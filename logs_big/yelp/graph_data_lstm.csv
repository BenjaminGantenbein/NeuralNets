train_loss,val_loss,val_accuracy
0.692206999834846,0.6795327365398407,79.25
0.6255740856423098,0.7010627388954163,58.5
0.518801864455728,0.6109769940376282,70.0
0.42055974637760835,0.4728996753692627,83.25
0.3751515851301305,0.49425871670246124,80.0
0.35371048836147084,0.4459264427423477,85.5
0.34328482957447276,0.44506463408470154,86.5
0.3350028167752659,0.4794112741947174,83.25
0.33163484755684347,0.4869813919067383,82.0
0.32575443912954893,0.4548295736312866,85.25
0.32191089146277485,0.463217556476593,83.25
0.3218096862821018,0.4944065809249878,81.0
0.3297581427237567,0.47592611610889435,83.5
0.32980510241845074,0.4607280492782593,84.25
0.32673782986753125,0.4525483250617981,85.25
0.31811899297377644,0.4405360072851181,85.5
0.31590603029026704,0.42758841812610626,89.0
0.31352419888272004,0.4245779514312744,88.75
0.3134343659176546,0.4238845258951187,88.75
0.31341564129380617,0.42367978394031525,88.75
0.31339822446598725,0.42349302768707275,88.75
0.3133935051805833,0.4234154671430588,88.75
0.3133707905516905,0.4233934134244919,88.75
0.31337297313353596,0.42339740693569183,88.75
0.31336113985847025,0.4233977943658829,88.75
0.31335508823394775,0.4235508441925049,88.75
0.3133431497742148,0.42351222038269043,88.75
0.3133346473469454,0.42349426448345184,88.75
0.3133402203812319,0.4235503077507019,88.75
0.3133333483163048,0.42362654209136963,88.75
0.3133332957239712,0.42373816668987274,88.75
0.31332558218170614,0.423773929476738,88.75
0.31332173592904033,0.42379532754421234,88.75
0.3133205596138449,0.4238135814666748,88.75
0.3133172182475819,0.4239070862531662,88.75
0.31331321071175966,0.42402155697345734,88.75
0.31330890515271353,0.42408934235572815,88.75
0.31330689261941347,0.4241519570350647,88.75
0.3133091470774482,0.4242010712623596,88.75
0.31330687333555785,0.4242061376571655,88.75


#END OF GRAPH
Reduced_DataSet: NO
Layers=2, Bidirectional = True
Learning Rate = 0.001
HiddenSize = 128
Adam



Training complete! Best accuracy: 89.00%.
FINISHED TRAINING
EVALUATING
Average test loss: 0.5101, Accuracy: 0.7900
Precision: 0.7990, Recall: 0.8003, F1-score: 0.7900, AUC-ROC: 0.8003
Confusion Matrix: 
[[39  5]
 [16 40]]
Classification Report: 
              precision    recall  f1-score   support

           0       0.71      0.89      0.79        44
           1       0.89      0.71      0.79        56

    accuracy                           0.79       100
   macro avg       0.80      0.80      0.79       100
weighted avg       0.81      0.79      0.79       100