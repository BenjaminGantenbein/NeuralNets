train_loss,val_loss,val_accuracy
0.6952775821966284,0.6944125294685364,51.0
0.6862132794716779,0.6854376792907715,53.0
0.6751613511758692,0.6710569560527802,51.75
0.6648130872670341,0.6580968797206879,55.25
0.6639952063560486,0.6503694653511047,57.75
0.6529722073498894,0.6363216638565063,57.5
0.6417987767387839,0.6313149929046631,60.0
0.6387537367203656,0.622002124786377,60.0
0.6295039197977852,0.6101777255535126,61.25
0.6171799407285803,0.6006261706352234,63.5
0.6149865599239573,0.5914001762866974,64.25
0.6040886745733374,0.5809117555618286,65.25
0.5985213833696702,0.5681017935276031,68.75
0.592457024490132,0.5564142465591431,70.0
0.577861487865448,0.5473491251468658,67.5
0.5726808134247275,0.5389413684606552,73.25
0.5627288993667153,0.5289618521928787,72.0
0.559146993300494,0.5145781636238098,74.0
0.5478087838958291,0.5033316910266876,76.25
0.5328477673670825,0.4968540221452713,76.5
0.5299894178614897,0.48994214832782745,77.5
0.5107294882045073,0.4811249375343323,77.5
0.5193096451899585,0.4737320989370346,76.5
0.516080312869128,0.46312080323696136,78.75
0.5047223971170538,0.45495735108852386,80.0
0.49689588827245373,0.45051512122154236,78.75
0.48744403264101815,0.4403717815876007,82.5
0.4713711054886089,0.434479296207428,82.5
0.4695216715335846,0.42848271131515503,82.5
0.46366516632192273,0.422200009226799,81.25
0.45550453662872314,0.41742515563964844,82.25
0.43736454143243675,0.4146292060613632,81.25
0.43736641196643605,0.4136723726987839,82.5
0.43915826082229614,0.4160615801811218,82.5
0.4196620057610905,0.4020889848470688,82.25
0.4136752135613385,0.40046165883541107,81.25
0.4128607756951276,0.3964206129312515,83.5
0.4021727881010841,0.39414649456739426,82.25
0.4094325444277595,0.3925912529230118,82.25
0.39524629799758687,0.38979631662368774,83.5



#END OF GRAPH
Reduced_DataSet: NO
Layers=1, Heads = 2
HiddenSize = 128
Learning Rate = 0.00001
Adam




Training complete! Best accuracy: 83.50%.
FINISHED TRAINING
EVALUATING
Average test loss: 0.3956, Accuracy: 0.8400
Precision: 0.8489, Recall: 0.8400, F1-score: 0.8390, AUC-ROC: 0.8400
Confusion Matrix: 
[[46  4]
 [12 38]]
Classification Report: 
              precision    recall  f1-score   support

           0       0.79      0.92      0.85        50
           1       0.90      0.76      0.83        50

    accuracy                           0.84       100
   macro avg       0.85      0.84      0.84       100
weighted avg       0.85      0.84      0.84       100
