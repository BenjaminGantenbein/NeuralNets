train_loss,val_loss,val_accuracy
0.6982159088639652,0.7006210386753082,43.25
0.6957821460331187,0.699942946434021,43.25
0.6936583308612599,0.696431964635849,43.25
0.6917949914932251,0.6952316761016846,43.25
0.6947433282347286,0.6945726275444031,43.25
0.6929062534781063,0.6930797696113586,46.75
0.6942695168887868,0.6956779956817627,43.25
0.6933137809529024,0.6989805102348328,43.25
0.6936502316418816,0.6971977353096008,43.25
0.6934177314533907,0.6965799033641815,43.25
0.692854148500106,0.7018151581287384,43.25
0.6921953138183145,0.6985692977905273,43.25
0.6912028088289148,0.6968242526054382,47.5
0.6894083969733295,0.692206472158432,50.25
0.6906507471028496,0.6963054835796356,46.0
0.6916552431443158,0.69505774974823,48.0
0.6906995633069206,0.693738579750061,45.5
0.6909531109473285,0.6924290955066681,49.0
0.6891703745898079,0.697484701871872,47.0
0.6885187976500567,0.6910373270511627,51.25
0.6852407245075002,0.7026621401309967,48.5
0.6819522065274856,0.6902365982532501,53.5
0.682260117110084,0.6950026452541351,47.75
0.6850851809277254,0.6895865797996521,52.25
0.68102786470862,0.6867009699344635,54.75
0.6746146573739893,0.6861823499202728,49.0
0.6774367655024809,0.6824948489665985,51.25
0.6767765774446375,0.7069860100746155,43.25
0.6679013511713814,0.7415805459022522,43.25
0.6570530533790588,0.6494032740592957,77.25
0.6660232263452867,0.7289619743824005,43.25
0.6403559095719281,0.8089733123779297,43.25
0.6472172526752248,0.6347591280937195,69.25
0.6369910134988672,0.6477555632591248,53.5
0.6282228652168723,0.6408331394195557,60.25
0.6294733180719263,0.5637227594852448,82.75
0.6225723974844989,0.8563051521778107,43.25
0.6102738888824687,0.6179895997047424,62.75
0.6000178719268126,0.6487772762775421,56.0
0.6046007065212026,0.6487610936164856,62.75


#END OF GRAPH
Reduced_DataSet: NO
HiddenSize = 64
Learning Rate = 0.9
Adam


Training complete! Best accuracy: 82.75%.
FINISHED TRAINING
EVALUATING
Average test loss: 0.5753, Accuracy: 0.7800
Precision: 0.7804, Recall: 0.7800, F1-score: 0.7799, AUC-ROC: 0.7800
Confusion Matrix: 
[[40 10]
 [12 38]]
Classification Report: 
              precision    recall  f1-score   support

           0       0.77      0.80      0.78        50
           1       0.79      0.76      0.78        50

    accuracy                           0.78       100
   macro avg       0.78      0.78      0.78       100
weighted avg       0.78      0.78      0.78       100
